{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Posao\\firebot-segmentation\\.env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "import time\n",
    "import string\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.rgb import mask2rgb\n",
    "from utils.prediction.evaluations import visualize, preload_image_data\n",
    "from utils.prediction.predict import Prediction\n",
    "\n",
    "# Logging\n",
    "from utils.logging import logging\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "log.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_models = [\n",
    "    { \n",
    "        'model_name': 'U-Net 256x256',\n",
    "        'model_path': r'checkpoints/avid-forest-323/best-checkpoint.pth.tar',\n",
    "        'patch_size': 256,\n",
    "    },\n",
    "    { \n",
    "        'model_name': 'U-Net 512x512',\n",
    "        'model_path': r'checkpoints/helpful-sky-334/best-checkpoint.pth.tar',\n",
    "        'patch_size': 512,\n",
    "    },\n",
    "   { \n",
    "        'model_name': 'U-Net 640x640',\n",
    "        'model_path': r'checkpoints/graceful-snowball-337/best-checkpoint.pth.tar',\n",
    "        'patch_size': 640,\n",
    "    }, \n",
    "    { \n",
    "        'model_name': 'U-Net 768x768',\n",
    "        'model_path': r'checkpoints/silvery-serenity-371/best-checkpoint.pth.tar',\n",
    "        'patch_size': 768,\n",
    "    },\n",
    "    { \n",
    "        'model_name': 'U-Net 800x800',\n",
    "        'model_path': r'checkpoints/kind-totem-369/best-checkpoint.pth.tar',\n",
    "        'patch_size': 800,\n",
    "    },\n",
    "    { \n",
    "        'model_name': 'U-Net 864x864',\n",
    "        'model_path': r'checkpoints/swept-field-374/best-checkpoint.pth.tar',\n",
    "        'patch_size': 864,\n",
    "    },\n",
    "    { \n",
    "        'model_name': 'U-Net 960x960',\n",
    "        'model_path': r'checkpoints/giddy-leaf-375/best-checkpoint.pth.tar',\n",
    "        'patch_size': 960,\n",
    "    },\n",
    "    { \n",
    "        'model_name': 'U-Net 1088x1088',\n",
    "        'model_path': r'checkpoints/masked-orb-376/best-checkpoint.pth.tar',\n",
    "        'patch_size': 1088,\n",
    "    },\n",
    "]\n",
    "metrics_model_index = 2\n",
    "\n",
    "metrics_output = pathlib.Path('metrics_output')\n",
    "model_metrics_output = pathlib.Path(metrics_output, metrics_models[metrics_model_index]['model_name'])\n",
    "\n",
    "# Create directory if it doesn't exists\n",
    "if not os.path.isdir(model_metrics_output):\n",
    "    os.makedirs(model_metrics_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA]: Started preloading test images and labels!\n"
     ]
    }
   ],
   "source": [
    "log.info('[DATA]: Started preloading test images and labels!')\n",
    "test_imgs, _ = preload_image_data(r'data', r'imgs', False, metrics_models[metrics_model_index]['patch_size'])\n",
    "test_labels, test_label_names = preload_image_data(r'data', r'imgs', True, metrics_models[metrics_model_index]['patch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREDICTION]: Loading model checkpoints/stellar-sun-400/best-checkpoint.pth.tar\n",
      "[PREDICTION]: Model loaded!\n",
      "[PREDICTION]: Starting prediction on 683 image(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 683/683 [00:34<00:00, 19.86it/s]\n"
     ]
    }
   ],
   "source": [
    "model_params = {\n",
    "    'model_name': metrics_models[metrics_model_index]['model_path'],\n",
    "    'patch_width': metrics_models[metrics_model_index]['patch_size'],\n",
    "    'patch_height': metrics_models[metrics_model_index]['patch_size'],\n",
    "    'n_channels': 3,\n",
    "    'n_classes': 3\n",
    "}\n",
    "model = Prediction(model_params)\n",
    "model.initialize()\n",
    "\n",
    "log.info('[PREDICTION]: Model loaded!')\n",
    "log.info(f'[PREDICTION]: Starting prediction on {len(test_imgs)} image(s).')\n",
    "\n",
    "predicted_labels = []\n",
    "img_process_time_list = []\n",
    "m_ious = []\n",
    "\n",
    "batch_start_time = time.time()\n",
    "pbar = tqdm.tqdm(enumerate(test_imgs), total=len(test_imgs))\n",
    "for i, img in pbar:\n",
    "    img_start_time = time.time()\n",
    "    mask_predict = model.predict_image(img)\n",
    "    img_process_time = time.time() - img_start_time\n",
    "\n",
    "    predicted_labels.append(mask_predict)\n",
    "    img_process_time_list.append(img_process_time)\n",
    "\n",
    "pbar.close()\n",
    "batch_process_time = time.time() - batch_start_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS]: Started calculating Jacaard Index!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 683/683 [00:07<00:00, 95.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[METRICS]: Started converting RGB masks to binary masks!\n",
      "[METRICS]: Started calculating Jacaard Index!\n",
      "[METRICS]: Done calculating Jacaard Index!\n",
      "Dice Score: 0.79885 | Max. Processing Time: 0.20ms | Avg. Processing Time: 0.05ms | Min. Processing Time: 0.05ms | Whole Processing Time: 34s\n"
     ]
    }
   ],
   "source": [
    "# Vars\n",
    "dice_scores = []\n",
    "\n",
    "log.info('[METRICS]: Started calculating Jacaard Index!')\n",
    "\n",
    "pbar = tqdm.tqdm(enumerate(test_labels), total=len(test_labels))\n",
    "for i, label in pbar:\n",
    "    # # Fire\n",
    "    # ground_truth_fire = cv2.inRange(label, 1, 1)\n",
    "    # prediction_fire = cv2.inRange(predicted_labels[i], 1, 1)\n",
    "\n",
    "    # gt_mapped_fire = ground_truth_fire.flatten().astype('float') / 255\n",
    "    # pred_mapped_fire = prediction_fire.flatten().astype('float') / 255\n",
    "\n",
    "    # dice_scores.append(jaccard_score(gt_mapped_fire, pred_mapped_fire))\n",
    "\n",
    "    # Smoke\n",
    "    ground_truth_smoke = cv2.inRange(label, 2, 2)\n",
    "    prediction_smoke = cv2.inRange(predicted_labels[i], 2, 2)\n",
    "\n",
    "    gt_mapped_smoke = ground_truth_smoke.flatten().astype('float') / 255\n",
    "    pred_mapped_smoke = prediction_smoke.flatten().astype('float') / 255\n",
    "\n",
    "    dice_scores.append(jaccard_score(gt_mapped_smoke, pred_mapped_smoke))\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "data = {}\n",
    "data['Image'] = test_label_names\n",
    "data[metrics_models[metrics_model_index]['model_name']] = dice_scores\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "# Global Vars\n",
    "# gt_flatten_fire, pred_flatten_fire = np.asarray(gt_list_fire).flatten(), np.asarray(pred_list_fire).flatten()\n",
    "# gt_flatten_smoke, pred_flatten_smoke = np.asarray(gt_list_smoke).flatten(), np.asarray(pred_list_smoke).flatten()\n",
    "\n",
    "# Remove Unused Data From Memory\n",
    "# log.info('[METRICS]: Started converting RGB masks to binary masks!')\n",
    "# del test_imgs\n",
    "# del test_labels\n",
    "\n",
    "# Calculate Metrics\n",
    "log.info('[METRICS]: Started calculating Jacaard Index!')\n",
    "dice_score = jaccard_score(gt_flatten_fire, pred_flatten_fire)\n",
    "log.info('[METRICS]: Done calculating Jacaard Index!')\n",
    "\n",
    "# String log evaluation metrics\n",
    "log.info(\n",
    "f'Dice Score: {np.mean(dice_score):.5f} | \\\n",
    "Max. Processing Time: {(np.amax(img_process_time_list) * 1000):.2f}ms | \\\n",
    "Avg. Processing Time: {(np.mean(img_process_time_list) * 1000):.2f}ms | \\\n",
    "Min. Processing Time: {(np.amin(img_process_time_list) * 1000):.2f}ms | \\\n",
    "Whole Processing Time: {(batch_process_time):.0f}s'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7eb2f6b845537a5839f8789b37e69e6155f5643919bcd7e9b333e352ddbc6d99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
